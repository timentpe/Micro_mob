{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8795a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme.expressions import Beta, Variable, log, exp\n",
    "from biogeme.results_processing import get_pandas_estimated_parameters\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30924178",
   "metadata": {},
   "source": [
    "## Data exploration and analysis preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669d50b",
   "metadata": {},
   "source": [
    "#### Reading the data and converting them into a Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4046182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 other dataframes and 12 sensors dataframes\n",
      "Sample other_road_users keys: ['ebike_subject_a', 'ebike_subject_b', 'escooter_subject_b', 'escooter_subject_c', 'ebike_subject_e', 'escooter_subject_e', 'ebike_subject_g', 'escooter_subject_g', 'ebike_subject_h', 'escooter_subject_h']\n",
      "Sample sensors keys: ['ebike_subject_a', 'ebike_subject_b', 'escooter_subject_b', 'escooter_subject_c', 'ebike_subject_e', 'escooter_subject_e', 'ebike_subject_g', 'escooter_subject_g', 'ebike_subject_h', 'escooter_subject_h']\n"
     ]
    }
   ],
   "source": [
    "# Load all dataframes (using data_loader module)\n",
    "\n",
    "from data_loader import load_dataset as load_all\n",
    "\n",
    "other_road_users, sensors = load_all()\n",
    "print('Loaded', len(other_road_users), 'other dataframes and', len(sensors), 'sensors dataframes')\n",
    "\n",
    "# Display sample keys\n",
    "print('Sample other_road_users keys:', list(other_road_users.keys())[:10])\n",
    "print('Sample sensors keys:', list(sensors.keys())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d96f9d",
   "metadata": {},
   "source": [
    "Beware : other_road_users is a dictionnary of dataframes, key = MMV_subject_x , value is associated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e083e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of other_road_users: ['frame_index', 'track_id', 'class_name', 'angle', 'distance', 'x', 'y', 'x_inter', 'y_inter', 'x_inter_rts', 'y_inter_rts', 'vx_rts', 'vy_rts', 'interpolated', 'corrected_class']\n",
      "Columns of sensors: ['timestamp', 'cts_gopro', 'date_gopro', 'GPS (Lat.) [deg]', 'GPS (Long.) [deg]', 'GPS (Alt.) [m]', 'GPS (2D speed) [m/s]', 'precision', 'cts_gyro', 'date_gyro', 'Gyroscope (z) [rad/s]', 'Gyroscope (x) [rad/s]', 'Gyroscope (y) [rad/s]', 'cts_acc', 'date_acc', 'Accelerometer (z) [m/s²]', 'Accelerometer (x) [m/s²]', 'Accelerometer (y) [m/s²]', 'Accelerometer (x) Filtered [m/s²]', 'Accelerometer (y) Filtered [m/s²]', 'Accelerometer (z) Filtered [m/s²]', 'Filtered velocity [m/s]', 'bearing', 'frame_index']\n"
     ]
    }
   ],
   "source": [
    "# See the columns of other_road_users dataframes\n",
    "print('Columns of other_road_users:', list(other_road_users['ebike_subject_a'].columns) )\n",
    "# See the columns of sensors dataframes\n",
    "print( 'Columns of sensors:', list(sensors['ebike_subject_b'].columns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb039759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the missing data in all the dataframes (Ghislain ajoute cette cellule après avoir chargé les dataframes)\n",
    "\n",
    "for key in other_road_users:\n",
    "    other_road_users[key] = other_road_users[key].dropna()\n",
    "for key in sensors:\n",
    "    sensors[key] = sensors[key].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e82a12",
   "metadata": {},
   "source": [
    "## Merging, feature creation, and broadcasting of static questionnaire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aaee9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 4651\n",
      "Columns: ['timestamp', 'cts_gopro', 'date_gopro', 'GPS (Lat.) [deg]', 'GPS (Long.) [deg]', 'GPS (Alt.) [m]', 'GPS (2D speed) [m/s]', 'precision', 'cts_gyro', 'date_gyro', 'Gyroscope (z) [rad/s]', 'Gyroscope (x) [rad/s]', 'Gyroscope (y) [rad/s]', 'cts_acc', 'date_acc', 'Accelerometer (z) [m/s²]', 'Accelerometer (x) [m/s²]', 'Accelerometer (y) [m/s²]', 'Accelerometer (x) Filtered [m/s²]', 'Accelerometer (y) Filtered [m/s²]', 'Accelerometer (z) Filtered [m/s²]', 'Filtered velocity [m/s]', 'bearing', 'frame_index', 'track_id', 'class_name', 'angle', 'distance', 'x', 'y', 'x_inter', 'y_inter', 'x_inter_rts', 'y_inter_rts', 'vx_rts', 'vy_rts', 'interpolated', 'corrected_class', 'vehicle_type', 'subject_id', 'closing_speed', 'iTTC', 'v_t_minus_1', 'CBQ_Violations']\n",
      "  subject_id vehicle_type  v_t_minus_1  distance  iTTC\n",
      "0  subject_a        ebike     2.026448      50.0   0.0\n",
      "1  subject_a        ebike     2.154997      50.0   0.0\n",
      "2  subject_a        ebike     2.280301      50.0   0.0\n",
      "3  subject_a        ebike     2.398887      50.0   0.0\n",
      "4  subject_a        ebike     2.507339      50.0   0.0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1. SETUP: ASSUMING DATA IS LOADED\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# List to store processed dataframes before final concatenation\n",
    "processed_frames = []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. ITERATE THROUGH SUBJECTS\n",
    "# -----------------------------------------------------------------------------\n",
    "# We iterate through the keys of the sensors dictionary\n",
    "for key in sensors.keys():\n",
    "    \n",
    "    # A. Extract DataFrames\n",
    "    # ---------------------\n",
    "    if key not in other_road_users:\n",
    "        print(f\"Warning: No user data found for {key}. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    df_sensor = sensors[key].copy()\n",
    "    df_user = other_road_users[key].copy()\n",
    "    \n",
    "    # Sort by timestamp/frame just to be safe\n",
    "    df_sensor = df_sensor.sort_values(by='timestamp')\n",
    "    \n",
    "    # B. Filter \"Other Road Users\" (Keep Closest Only)\n",
    "    # ------------------------------------------------\n",
    "    # We only want one interaction per timestamp for the simple regression model.\n",
    "    # We sort by frame_index and distance, then keep the first (closest).\n",
    "    df_user_sorted = df_user.sort_values(by=['frame_index', 'distance'])\n",
    "    df_user_closest = df_user_sorted.drop_duplicates(subset=['frame_index'], keep='first')\n",
    "    \n",
    "    # C. Merge\n",
    "    # --------\n",
    "    # Left merge: We keep all sensor data (rider state), \n",
    "    # and attach pedestrian data where available.\n",
    "    df_merged = pd.merge(df_sensor, df_user_closest, on='frame_index', how='left')\n",
    "    \n",
    "    # D. Metadata Parsing (From Key)\n",
    "    # ------------------------------\n",
    "    # Keys are like 'ebike_subject_a' or 'escooter_subject_b'\n",
    "    # We split the string to get vehicle type and subject ID\n",
    "    parts = key.split('_') # ['ebike', 'subject', 'a']\n",
    "    \n",
    "    vehicle_type = parts[0] # 'ebike' or 'escooter'\n",
    "    subject_id = f\"{parts[1]}_{parts[2]}\" # 'subject_a'\n",
    "    \n",
    "    df_merged['vehicle_type'] = vehicle_type\n",
    "    df_merged['subject_id'] = subject_id\n",
    "    \n",
    "    # E. Feature Engineering (Physics)\n",
    "    # --------------------------------\n",
    "    \n",
    "    # 1. Handle Missing Detection Data\n",
    "    # If no pedestrian detected, distance is infinite (safe). \n",
    "    # We use 50m as a \"max relevant distance\".\n",
    "    df_merged['distance'] = df_merged['distance'].fillna(50.0)\n",
    "    df_merged['angle'] = df_merged['angle'].fillna(0.0)\n",
    "    \n",
    "    # 2. Closing Speed (m/s)\n",
    "    # 'vx_rts' is usually the relative velocity in X. \n",
    "    # If x decreases (getting closer), vx is negative.\n",
    "    # Closing speed = -1 * Relative Velocity (so positive means closing in)\n",
    "    df_merged['vx_rts'] = df_merged['vx_rts'].fillna(0.0)\n",
    "    df_merged['closing_speed'] = -1 * df_merged['vx_rts']\n",
    "    \n",
    "    # 3. Inverse Time-To-Collision (iTTC)\n",
    "    # iTTC = Closing Speed / Distance\n",
    "    # We use Inverse because TTC is infinite when safe (causes math errors).\n",
    "    # iTTC = 0 means safe/infinite time. High value means danger.\n",
    "    # We only calculate if closing_speed > 0 (getting closer).\n",
    "    condition_danger = (df_merged['closing_speed'] > 0) & (df_merged['distance'] > 0.1)\n",
    "    \n",
    "    df_merged['iTTC'] = np.where(\n",
    "        condition_danger,\n",
    "        df_merged['closing_speed'] / df_merged['distance'],\n",
    "        0.0\n",
    "    )\n",
    "    \n",
    "    # F. Lagged Variables (Auto-regression)\n",
    "    # -------------------------------------\n",
    "    # We calculate this HERE, inside the loop, so the last second of \n",
    "    # Subject A doesn't become the \"previous speed\" for Subject B.\n",
    "    \n",
    "    # Predictor: Speed at t-1\n",
    "    df_merged['v_t_minus_1'] = df_merged['Filtered velocity [m/s]'].shift(1)\n",
    "    \n",
    "    # Target: Acceleration at t (already exists), but let's ensure units are clean\n",
    "    # 'Accelerometer (x) Filtered' is our Y\n",
    "    \n",
    "    # Drop the first row of this subject (NaN due to shift)\n",
    "    df_merged = df_merged.dropna(subset=['v_t_minus_1'])\n",
    "    \n",
    "    # Add to list\n",
    "    processed_frames.append(df_merged)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. CONCATENATE FINAL DATASET\n",
    "# -----------------------------------------------------------------------------\n",
    "final_dataset = pd.concat(processed_frames, ignore_index=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. (Optional) MAPPING STATIC QUESTIONNAIRES\n",
    "# -----------------------------------------------------------------------------\n",
    "# If you have the scores, map them now using the 'subject_id' column created in Step D.\n",
    "# Example dictionary (You need to fill this with real values from the questionnaires):\n",
    "cbq_scores = {\n",
    "    'subject_a': 1.2, 'subject_b': 3.5, 'subject_c': 0.8,\n",
    "    'subject_e': 2.1, 'subject_g': 1.5, 'subject_h': 4.0\n",
    "}\n",
    "\n",
    "# Map new column\n",
    "final_dataset['CBQ_Violations'] = final_dataset['subject_id'].map(cbq_scores)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. INSPECT\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"Total rows: {len(final_dataset)}\")\n",
    "print(\"Columns:\", final_dataset.columns.tolist())\n",
    "print(final_dataset[['subject_id', 'vehicle_type', 'v_t_minus_1', 'distance', 'iTTC']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b66c6f",
   "metadata": {},
   "source": [
    "## Model 1 : Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b4aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns for Biogeme: ['timestamp', 'cts_gopro', 'date_gopro', 'GPS (Lat.) [deg]', 'GPS (Long.) [deg]', 'GPS (Alt.) [m]', 'GPS (2D speed) [m/s]', 'precision', 'cts_gyro', 'date_gyro', 'Gyroscope (z) [rad/s]', 'Gyroscope (x) [rad/s]', 'Gyroscope (y) [rad/s]', 'cts_acc', 'date_acc', 'Accelerometer (z) [m/s²]', 'Accelerometer (x) [m/s²]', 'Accelerometer (y) [m/s²]', 'Acc_X', 'Accelerometer (y) Filtered [m/s²]', 'Accelerometer (z) Filtered [m/s²]', 'Speed', 'bearing', 'frame_index', 'track_id', 'class_name', 'angle', 'Distance', 'x', 'y', 'x_inter', 'y_inter', 'x_inter_rts', 'y_inter_rts', 'vx_rts', 'vy_rts', 'interpolated', 'corrected_class', 'vehicle_type', 'subject_id', 'closing_speed', 'Inv_TTC', 'Speed_Lag', 'CBQ_Violations']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4424/1561534422.py:52: DeprecationWarning: 'modelName' is deprecated. Please use 'model_name' instead.\n",
      "  biogeme_obj.modelName = \"micromobility_linear_regression\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model micromobility_linear_regression\n",
      "Nbr of parameters:\t\t5\n",
      "Sample size:\t\t\t4651\n",
      "Excluded data:\t\t\t0\n",
      "Final log likelihood:\t\t-5077.235\n",
      "Akaike Information Criterion:\t10164.47\n",
      "Bayesian Information Criterion:\t10196.69\n",
      "\n",
      "          Name     Value  Robust std err.  Robust t-stat.  Robust p-value\n",
      "0      B_Sigma  0.720872         0.010790       66.807109    0.000000e+00\n",
      "1  B_Intercept  0.231235         0.031923        7.243598    4.369838e-13\n",
      "2   B_SpeedLag -0.027394         0.008554       -3.202483    1.362481e-03\n",
      "3   B_Distance  0.001065         0.000491        2.168825    3.009594e-02\n",
      "4       B_iTTC  0.072894         0.066573        1.094950    2.735386e-01\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare Data for Biogeme\n",
    "# Biogeme does not handle spaces/parentheses in column names well.\n",
    "# We rename the columns from the 'final_dataset' created in the previous step.\n",
    "df_bio = final_dataset.rename(columns={\n",
    "    'Accelerometer (x) Filtered [m/s²]': 'Acc_X',\n",
    "    'Filtered velocity [m/s]': 'Speed',\n",
    "    'v_t_minus_1': 'Speed_Lag',\n",
    "    'distance': 'Distance',\n",
    "    'iTTC': 'Inv_TTC'\n",
    "})\n",
    "\n",
    "print(\"Columns for Biogeme:\", df_bio.columns.tolist())\n",
    "\n",
    "df_bio = df_bio[['Acc_X', 'Speed_Lag', 'Distance', 'Inv_TTC']]\n",
    "\n",
    "# 2. Initialize Biogeme Database\n",
    "database = db.Database(\"micromobility_linear_model\", df_bio)\n",
    "\n",
    "# 3. Define Parameters to Estimate (Name, Start Value, LowerBound, UpperBound, Fixed)\n",
    "B_Intercept = Beta('B_Intercept', 0, None, None, 0)\n",
    "B_SpeedLag  = Beta('B_SpeedLag', 0, None, None, 0)  # Autoregressive term\n",
    "B_Distance  = Beta('B_Distance', 0, None, None, 0)  # Influence of proximity\n",
    "B_iTTC      = Beta('B_iTTC', 0, None, None, 0)      # Influence of collision risk\n",
    "B_Sigma     = Beta('B_Sigma', 1, None, None, 0)     # Standard deviation of error\n",
    "\n",
    "# 4. Define Variables from Database\n",
    "Acc_X     = Variable('Acc_X')\n",
    "Speed_Lag = Variable('Speed_Lag')\n",
    "Distance  = Variable('Distance')\n",
    "Inv_TTC   = Variable('Inv_TTC')\n",
    "\n",
    "# 5. Model Specification (Linear Regression)\n",
    "# Model: Acc(t) = B0 + B1*Speed(t-1) + B2*Distance + B3*iTTC + epsilon\n",
    "Utility = B_Intercept + \\\n",
    "             (B_SpeedLag * Speed_Lag) + \\\n",
    "             (B_Distance * Distance) + \\\n",
    "             (B_iTTC * Inv_TTC)\n",
    "\n",
    "# 6. Likelihood Function (Normal Distribution)\n",
    "# We maximize the likelihood that the errors are normally distributed.\n",
    "likelihood = -0.5 * log(2 * 3.14159) - log(B_Sigma) - \\\n",
    "             0.5 * ((Acc_X - Utility) / B_Sigma)**2\n",
    "\n",
    "# 7. Estimate\n",
    "biogeme_obj = bio.BIOGEME(database, likelihood)\n",
    "biogeme_obj.modelName = \"micromobility_linear_regression\"\n",
    "results = biogeme_obj.estimate()\n",
    "\n",
    "# 8. Print Results\n",
    "print(results.short_summary())\n",
    "print(get_pandas_estimated_parameters(estimation_results=results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283171ad",
   "metadata": {},
   "source": [
    "## Model 2 : Radom forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5685402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in final_dataset: ['timestamp', 'cts_gopro', 'date_gopro', 'GPS (Lat.) [deg]', 'GPS (Long.) [deg]', 'GPS (Alt.) [m]', 'GPS (2D speed) [m/s]', 'precision', 'cts_gyro', 'date_gyro', 'Gyroscope (z) [rad/s]', 'Gyroscope (x) [rad/s]', 'Gyroscope (y) [rad/s]', 'cts_acc', 'date_acc', 'Accelerometer (z) [m/s²]', 'Accelerometer (x) [m/s²]', 'Accelerometer (y) [m/s²]', 'Accelerometer (x) Filtered [m/s²]', 'Accelerometer (y) Filtered [m/s²]', 'Accelerometer (z) Filtered [m/s²]', 'Filtered velocity [m/s]', 'bearing', 'frame_index', 'track_id', 'class_name', 'angle', 'distance', 'x', 'y', 'x_inter', 'y_inter', 'x_inter_rts', 'y_inter_rts', 'vx_rts', 'vy_rts', 'interpolated', 'corrected_class', 'vehicle_type', 'subject_id', 'closing_speed', 'iTTC', 'v_t_minus_1', 'CBQ_Violations', 'is_escooter']\n",
      "--- Random Forest Results ---\n",
      "Mean Squared Error: 0.3941\n",
      "R^2 Score: 0.1693\n",
      "Feature: v_t_minus_1, Importance: 0.4552\n",
      "Feature: distance, Importance: 0.1457\n",
      "Feature: angle, Importance: 0.1631\n",
      "Feature: iTTC, Importance: 0.0876\n",
      "Feature: is_escooter, Importance: 0.1484\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare Features (X) and Target (y)\n",
    "# We use the raw 'final_dataset' from the previous step.\n",
    "\n",
    "# Create a numeric dummy variable for vehicle type\n",
    "# 1 if E-scooter, 0 if E-bike\n",
    "final_dataset['is_escooter'] = (final_dataset['vehicle_type'] == 'escooter').astype(int)\n",
    "\n",
    "features = [\n",
    "    'v_t_minus_1',   # Lagged Speed (State)\n",
    "    'distance',      # Distance to pedestrian (Context)\n",
    "    'angle',         # Angle to pedestrian (Context)\n",
    "    'iTTC',          # Inverse Time to Collision (Interaction)\n",
    "    'is_escooter'    # Vehicle Type (Control)\n",
    "]\n",
    "\n",
    "print(\"Columns in final_dataset:\", final_dataset.columns.tolist())\n",
    "\n",
    "target = 'Accelerometer (x) Filtered [m/s²]'\n",
    "\n",
    "# Drop rows with NaN in these specific columns to ensure clean training\n",
    "df_rf = final_dataset.dropna(subset=features + [target])\n",
    "\n",
    "X = df_rf[features]\n",
    "y = df_rf[target]\n",
    "\n",
    "# 2. Train/Test Split (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Initialize Random Forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,  # Number of trees\n",
    "    max_depth=10,      # Limit depth to prevent overfitting\n",
    "    random_state=42,\n",
    "    n_jobs=-1          # Parallel processing\n",
    ")\n",
    "\n",
    "# 4. Train the Model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"--- Random Forest Results ---\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")\n",
    "\n",
    "# 6. Feature Importance (Interpretation)\n",
    "importances = rf_model.feature_importances_\n",
    "for name, importance in zip(features, importances):\n",
    "    print(f\"Feature: {name}, Importance: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593329c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choice_mod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
